# -*- coding: utf-8 -*-
"""Jumia_web_Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VeexrmGSZhhKlaD4gQgnm7CPSvMQxnmI
"""

from bs4 import BeautifulSoup
import pandas as pd

# Path to the downloaded HTML file
html_file_path = 'mobile_phones.html'

# Open and read the HTML file
with open(html_file_path, 'r', encoding='utf-8') as file:
    content = file.read()

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(content, 'html.parser')

# Extract product details
products = []
items = soup.find_all('article', class_="prd _fb col c-prd")
for item in items:
    product_name = item.find('h3', class_="name").text
    product_price = item.find('div', class_="prc").text
    product_link = item.find('a', class_="core")['href']

    # Append data to the list
    products.append({
        "Product Name": product_name,
        "Price": product_price,
        "Link": "https://www.jumia.com.eg" + product_link
    })

# Convert list to DataFrame for easy viewing and manipulation
df = pd.DataFrame(products)

# Display DataFrame
print(df)

# Save DataFrame to an Excel file
output_file = 'jumia_mobile_products.xlsx'
df.to_excel(output_file, index=False)

print(f"Data saved to {output_file}")

# Commented out IPython magic to ensure Python compatibility.
# Step 1: Set up Git configuration
!git config --global user.name "Alaa Orabi"
!git config --global user.email "alaaabdelfattah63@gmail.com"

# Step 2: Clone the repository
!git clone https://github.com/AlaaOrabi/JumiaWebScraping.git
# %cd JumiaWebScraping

# Step 3: Add, commit, and push changes
!git add .
!git commit -m "Add scraping code for Jumia mobile products"
!git push